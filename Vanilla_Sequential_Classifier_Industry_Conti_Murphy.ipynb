{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ],
      "metadata": {
        "id": "XEbZciTigoUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor"
      ],
      "metadata": {
        "id": "G9mN-iSokG8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxd_Jf24kG8h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from polyglot.text import Text\n",
        "from polyglot.detect.base import logger as polyglot_logger\n",
        "polyglot_logger.setLevel(\"ERROR\")\n",
        "\n",
        "from copy import copy\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "import re "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the data "
      ],
      "metadata": {
        "id": "MKN6krDPmyhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://drive.google.com/file/d/1-6E4h5lH2AHRUBVJUtchXSggMRYr_-8F/view?usp=share_link'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
        "\n",
        "df = pd.read_csv(path).dropna()\n",
        "df = df.drop_duplicates('text')\n",
        "df"
      ],
      "metadata": {
        "id": "M9LL1mr7mwgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3934d7e6-6b7c-479a-caaf-52cbabf7347b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                       speaker  \\\n",
              "0             0             Roselyne Bachelot   \n",
              "1             1                          None   \n",
              "2             2             Roselyne Bachelot   \n",
              "3             3                          None   \n",
              "4             4             Roselyne Bachelot   \n",
              "..          ...                           ...   \n",
              "785         126  Marjolaine Meynier-Millefert   \n",
              "786         127                          None   \n",
              "787         128                          None   \n",
              "788         129                          None   \n",
              "789         130                          None   \n",
              "\n",
              "                                                  text  \n",
              "0    Roselyne Bachelot en campagne à Angoulême : \" ...  \n",
              "1    C'est un métier et à ce jeu, elle a quelques k...  \n",
              "2    * Roselyne Bachelot en campagne à Angoulême : ...  \n",
              "3    \\n\\nC 'est un métier et à ce jeu, elle a quelq...  \n",
              "4    \\n\\n* La graine de l'expérience *\\n\\nUn style ...  \n",
              "..                                                 ...  \n",
              "785  \\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...  \n",
              "786  \\n\\nHabituellement, le samedi matin est un mom...  \n",
              "787  Présidentielle : à Beauvais, le ministre Franc...  \n",
              "788  Le ministre du Commerce extérieur et de l'Attr...  \n",
              "789  Par Patrick Caffin\\n\\nPour les soutiens d'Emma...  \n",
              "\n",
              "[790 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d27dd66-a94c-4fc6-aec3-e56e031e0b04\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>Roselyne Bachelot en campagne à Angoulême : \" ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>C'est un métier et à ce jeu, elle a quelques k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>* Roselyne Bachelot en campagne à Angoulême : ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nC 'est un métier et à ce jeu, elle a quelq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>\\n\\n* La graine de l'expérience *\\n\\nUn style ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785</th>\n",
              "      <td>126</td>\n",
              "      <td>Marjolaine Meynier-Millefert</td>\n",
              "      <td>\\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>127</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nHabituellement, le samedi matin est un mom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>128</td>\n",
              "      <td>None</td>\n",
              "      <td>Présidentielle : à Beauvais, le ministre Franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>129</td>\n",
              "      <td>None</td>\n",
              "      <td>Le ministre du Commerce extérieur et de l'Attr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>130</td>\n",
              "      <td>None</td>\n",
              "      <td>Par Patrick Caffin\\n\\nPour les soutiens d'Emma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>790 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d27dd66-a94c-4fc6-aec3-e56e031e0b04')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d27dd66-a94c-4fc6-aec3-e56e031e0b04 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d27dd66-a94c-4fc6-aec3-e56e031e0b04');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating train and test sets\n",
        "\n"
      ],
      "metadata": {
        "id": "-EKzlK_Fm8F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing and aligning output IOB tags"
      ],
      "metadata": {
        "id": "EIaRerC7kf4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tags'] = df[['speaker', 'text']].apply(lambda x: ['I' if word in set(re.findall('[\\w]+',x.speaker)) else 'O' for word in Text(x.text).words], axis=1 )\n",
        "df['tokenized_text'] = df['text'].apply(lambda x: Text(x).words)\n",
        "df = df[df.tokenized_text.apply(lambda x: len(x) < 200)]\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "o7N9uMSoyng2",
        "outputId": "e8827c24-83dd-4163-e282-9ed7fd601898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                               speaker  \\\n",
              "0           0                     Roselyne Bachelot   \n",
              "1           1                                  None   \n",
              "2           2                     Roselyne Bachelot   \n",
              "4           4                     Roselyne Bachelot   \n",
              "5           5  Roselyne Bachelot, Stanislas Guerini   \n",
              "\n",
              "                                                text  \\\n",
              "0  Roselyne Bachelot en campagne à Angoulême : \" ...   \n",
              "1  C'est un métier et à ce jeu, elle a quelques k...   \n",
              "2  * Roselyne Bachelot en campagne à Angoulême : ...   \n",
              "4  \\n\\n* La graine de l'expérience *\\n\\nUn style ...   \n",
              "5  \\n\\nLa politique étrangère, justement. Une béq...   \n",
              "\n",
              "                                                tags  \\\n",
              "0            [I, I, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2  [O, I, I, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "5  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [Roselyne, Bachelot, en, campagne, à, Angoulêm...  \n",
              "1  [C'est, un, métier, et, à, ce, jeu, ,, elle, a...  \n",
              "2  [*, Roselyne, Bachelot, en, campagne, à, Angou...  \n",
              "4  [*, La, graine, de, l'expérience, *, Un, style...  \n",
              "5  [La, politique, étrangère, ,, justement, ., Un...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-363d94ed-8cbd-4047-a4e3-589e27b5f274\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>Roselyne Bachelot en campagne à Angoulême : \" ...</td>\n",
              "      <td>[I, I, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Roselyne, Bachelot, en, campagne, à, Angoulêm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>C'est un métier et à ce jeu, elle a quelques k...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[C'est, un, métier, et, à, ce, jeu, ,, elle, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>* Roselyne Bachelot en campagne à Angoulême : ...</td>\n",
              "      <td>[O, I, I, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[*, Roselyne, Bachelot, en, campagne, à, Angou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>\\n\\n* La graine de l'expérience *\\n\\nUn style ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[*, La, graine, de, l'expérience, *, Un, style...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Roselyne Bachelot, Stanislas Guerini</td>\n",
              "      <td>\\n\\nLa politique étrangère, justement. Une béq...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[La, politique, étrangère, ,, justement, ., Un...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-363d94ed-8cbd-4047-a4e3-589e27b5f274')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-363d94ed-8cbd-4047-a4e3-589e27b5f274 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-363d94ed-8cbd-4047-a4e3-589e27b5f274');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "test_length  = int(df.shape[0] * 0.15)\n",
        "\n",
        "test         = df[:test_length]\n",
        "dev          = df[test_length:2*test_length]\n",
        "train        = df[2*test_length:]\n",
        "\n",
        "print(test.shape)\n",
        "print(dev.shape)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "id": "aWKC7uJPnVTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2075f9-46df-43a1-91a8-8c88adadf441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(103, 5)\n",
            "(103, 5)\n",
            "(482, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization and computation of input and output vocabulary"
      ],
      "metadata": {
        "id": "YNSb2R_Eqi3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making character vocabulary \n",
        "def vocabulary(df, input_vocab, padding='<pad>', unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token \n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "\n",
        "    if input_vocab:\n",
        "      sequences_list = df['tokenized_text'].to_list()\n",
        "    else:\n",
        "      sequences_list = df['tags'].to_list()\n",
        "\n",
        "    # Creates the mapping from ids to symbols (a list)\n",
        "    idx2sym = list({element.strip() for sequence in sequences_list for element in sequence})\n",
        "\n",
        "    # Decides whether to include the unknown token\n",
        "    if unknown:\n",
        "      idx2sym.append(unknown)\n",
        "\n",
        "    # Decides whether to include the padding token\n",
        "    if padding:\n",
        "      idx2sym.append(padding)\n",
        "\n",
        "    # Creates the mapping from symbols to ids (a dictionary)\n",
        "    sym2idx = {idx2sym[j]: j for j in range(len(idx2sym))}\n",
        "\n",
        "    # Return the two vocabulary maps idx2sym and sym2idx as a couple\n",
        "    return idx2sym, sym2idx   "
      ],
      "metadata": {
        "id": "YS335uhLsqaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "idx2sym, sym2idx  = vocabulary(df,True,padding=None,unknown=None)\n",
        "print(sym2idx)"
      ],
      "metadata": {
        "id": "kSvUVr8X0DVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding and decoding sequences "
      ],
      "metadata": {
        "id": "EeEQSmEq3Vs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens to match pad_size if needed\n",
        "    return [sequence[i] if i<len(sequence) else pad_token for i in range(pad_size)]\n",
        "   \n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    return [coding_map[symbol] if symbol in coding_map else coding_map[unk_token] for symbol in sequence]\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings \n",
        "    return [decoding_map[id] for id in sequence]"
      ],
      "metadata": {
        "id": "Tyz_WtyS3VJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloader (batch generator)"
      ],
      "metadata": {
        "id": "c0yxrmY5nWE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_examples(df):\n",
        "    \"\"\"\n",
        "    Returns a list of sentences and a list of tags.\n",
        "    A sentence is a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    paragraphs = df['text'].apply(lambda x: Text(x).words).to_list()\n",
        "    paragraphs = [[word.strip() for word in paragraph] for paragraph in paragraphs]\n",
        "\n",
        "    tags = df['speaker'].str.split(',').to_list()\n",
        "    tags = [[tag.strip() for tag in paragraph_tags] for paragraph_tags in tags]\n",
        "\n",
        "    assert len(paragraphs) == len(tags)\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(len(paragraphs)):\n",
        "        while(tags[i]):\n",
        "            X.append(paragraphs[i])\n",
        "            Y.append([tags[i].pop()])\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "PXc09u1acNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator:\n",
        "\n",
        "        def __init__(self, df, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx \n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym \n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx \n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym  \n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  # Creates 4 encoding maps from datafile \n",
        "                  self.input_idx2sym, self.input_sym2idx  = vocabulary(df, \n",
        "                                                                       input_vocab=True)\n",
        "                  self.output_idx2sym,self.output_sym2idx = vocabulary(df, \n",
        "                                                                       input_vocab=False,\n",
        "                                                                       padding=None)\n",
        "\n",
        "              # Stores the dataset with sentence structure (a list of lists of strings) in the following fields \n",
        "              self.Xtokens = df['tokenized_text'].to_list()\n",
        "              self.Ytokens = df['tags'].to_list()\n",
        "      \n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #Batches are lists of lists\n",
        "              \n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "              \n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #If we don't shuffle the train set after each epoch, the model may not converge\n",
        "              shuffle(idxes)\n",
        "              #For efficiency reasons, it is nice to have batches with a similar nb of elements,\n",
        "              #so we don't do useless computations over the padding token\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend] \n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)              \n",
        "              \n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx], batch_len, self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx,unk_token=self.unk_token) for seq in seqY]\n",
        "                 \n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ],
      "metadata": {
        "id": "HZXHCrZM2xYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model \n",
        "- LSTM encoding of paragraphs \n",
        "- IOB tagging"
      ],
      "metadata": {
        "id": "vFVUtZQiniWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    \n",
        "    def __init__(self, patience=7, verbose=True):\n",
        "        \"\"\"\n",
        "        patience (int): How long to wait after last time validation loss improved.\n",
        "                        Default: 7    \n",
        "        verbose (bool): Whether to print a message when early stop is activated.\n",
        "                        Default: True       \n",
        "        \"\"\"\n",
        "        self.patience       = patience\n",
        "        self.counter        = 0         # number of epochs since last improvement\n",
        "        self.best_loss      = None\n",
        "        self.best_accuracy  = None\n",
        "        self.verbose        = verbose\n",
        "\n",
        "    def __call__(self, val_loss, val_accuracy):\n",
        "        \"\"\"\n",
        "        val_loss (float): Validation loss obtained in the current epoch\n",
        "        val_accuracy (float): Validation accuracy obtained in the current epoch (used only for information, early stopping is based on loss)\n",
        "        \"\"\"\n",
        "        if self.best_loss is None:  # if first iteration\n",
        "            self.best_loss      = val_loss\n",
        "            self.best_accuracy  = val_accuracy\n",
        "\n",
        "        if val_loss < self.best_loss: # if improvement\n",
        "            self.best_loss      = val_loss\n",
        "            self.counter        = 0\n",
        "\n",
        "        if val_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy  = val_accuracy  # just for information\n",
        "\n",
        "        if val_loss > self.best_loss: # if no improvement\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "              if self.verbose:\n",
        "                print(\"\\nEARLY STOP\\n\")\n",
        "              return True\n",
        "\n",
        "        return False"
      ],
      "metadata": {
        "id": "nUyOCNf1ne_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core part\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator,embedding_size,hidden_size,device='cpu',\n",
        "                   patience=7,bidirectional=True,verbose=True):\n",
        "        super(NERtagger, self).__init__()        \n",
        "        self.embedding_size    = embedding_size\n",
        "        self.hidden_size       = hidden_size\n",
        "        self.bidirectional     = bidirectional  # whether the lstm is bidirectional or not\n",
        "        self.verbose           = verbose\n",
        "        self.allocate_params(traingenerator,device) \n",
        "        self.early_stopping    = EarlyStopping(verbose=verbose,patience=patience)\n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device):\n",
        "        # Creates fields for nn Layers\n",
        "\n",
        "        invocab_size   = len(datagenerator.input_idx2sym)\n",
        "        pad_idx        = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "        outvocab_size  = len(datagenerator.output_idx2sym)\n",
        "        \n",
        "        self.embeddings = nn.Embedding(invocab_size,\n",
        "                                      self.embedding_size,\n",
        "                                      padding_idx=pad_idx).to(device)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
        "                            hidden_size=self.hidden_size,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=self.bidirectional).to(device) \n",
        "                            # batch_first so it takes input of shape (batch, seq, feature)\n",
        "        \n",
        "        size_X         = self.hidden_size*2 if self.bidirectional else self.hidden_size # this line is necessary so the bidirectional switch works\n",
        "        self.output    = nn.Linear(size_X,outvocab_size).to(device)\n",
        " \n",
        "\n",
        "      def forward(self,X):\n",
        "        # X is of shape batch_size x sequence_length\n",
        "\n",
        "        # Prediction steps:\n",
        "        # embedded_X of shape batch_size x sequence_length x embedding_size\n",
        "        embedded_X  = self.embeddings(X)\n",
        "\n",
        "        # lstm_encodings of shape batch_size x sequence_length x lstm_hidden_size\n",
        "        lstm_encodings, (_, _) = self.lstm(embedded_X) \n",
        "\n",
        "        # output of shape batch_size x outvocab_size\n",
        "        return self.output(lstm_encodings) \n",
        "\n",
        "\n",
        "      def evaluate(self, datagenerator, batch_size = 64, device = 'cpu'): \n",
        "        '''evaluates the performance of the model on a test set. \n",
        "        calculates recall and precision, considering 'O' tags to be the negative case \n",
        "        and all i tags to be positice cases '''\n",
        "        self.to(device)\n",
        "        #self.eval()\n",
        "        true_neg = 0 \n",
        "        true_pos = 0 \n",
        "        false_neg = 0 \n",
        "        false_pos = 0 \n",
        "        pad_idx   = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "\n",
        "        for batch_x, batch_y in datagenerator.generate_batches(batch_size): \n",
        "          with torch.no_grad():\n",
        "            X_in    = torch.tensor(batch_x).to(device) #batch_size x seq_length\n",
        "            #print(f'x_in: {X_in.shape}')\n",
        "            y_gold  = torch.tensor(batch_y).to(device) #batch_size*seq_length\n",
        "            #print('y gold: ', y_gold.shape) \n",
        "            y_gold  = y_gold.view(-1) #batch_size*seq_length\n",
        "            #print('y gold: ', y_gold.shape) \n",
        "            Yhat    = self.forward(X_in) #batch_size x seq_length x outvocab size \n",
        "            #print(f'yhat: {Yhat.shape}')\n",
        "            y_pred = torch.argmax(Yhat, dim = 2) #batch_size x seq_length x 1\n",
        "            #print(f'ypred: {y_pred.shape}')\n",
        "            y_pred = y_pred.view(-1)\n",
        "            #print('y pred ', y_pred.shape)\n",
        "\n",
        "            pad_mask   = (y_gold != pad_idx)\n",
        "            pos_mask   = (y_pred != datagenerator.output_sym2idx['O'])\n",
        "            neg_mask   = (y_pred == datagenerator.output_sym2idx['O'])\n",
        "\n",
        "\n",
        "            true_pos  += torch.sum((y_pred==y_gold)*pos_mask*pad_mask)\n",
        "            #print('true_pos: ', true_pos)\n",
        "            true_neg  += torch.sum((y_pred == y_gold)*neg_mask*pad_mask)\n",
        "            #print('true negL ', true_neg)\n",
        "            false_pos += torch.sum((y_pred != y_gold)*pos_mask*pad_mask)\n",
        "            #print('false pos: ', false_pos)\n",
        "            false_neg += torch.sum((y_pred != y_gold)*neg_mask*pad_mask)\n",
        "            #print('false neg: ', false_neg)\n",
        "\n",
        "        precision = true_pos/(true_pos+false_pos)\n",
        "        recall    = true_pos/(true_pos+false_neg)\n",
        "        f_score   = 2*((precision*recall)/(precision+recall))\n",
        "        return precision, recall, f_score \n",
        "\n",
        "        \n",
        "      def train(self,traingenerator,validgenerator,epochs,batch_size,device='cpu'): \n",
        "\n",
        "        self.minloss = 10000000 # the min loss found so far on validation data\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        \n",
        "        device    = torch.device(device)\n",
        "        pad_index = traingenerator.input_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "          self.training = True  # Tells PyTorch we are in training mode (so dropout is activated).\n",
        "\n",
        "          epoch_loss = []\n",
        "          batch_accuracies = []\n",
        "          for seqX,seqY in traingenerator.generate_batches(batch_size):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            #input(f'x: {seqX}\\ny:{seqY}')\n",
        "            X = torch.LongTensor(seqX).to(device)\n",
        "            # Y is of shape batch_size x seq_length\n",
        "            Y = torch.LongTensor(seqY).to(device).view(-1)\n",
        "            #input(f'y gold: {Y.shape}')\n",
        "\n",
        "            # Yhat is of shape batch_size x seq_length x nb_classes\n",
        "            \n",
        "            Yhat = self.forward(X)\n",
        "            #input(f'YHAT initial: {Yhat.shape}')\n",
        "            num_inputs, seq_length, _ = Yhat.shape\n",
        "            Yhat = Yhat.view(num_inputs*seq_length, -1)\n",
        "            #input(f'YHAT reshaped: {Yhat.shape}')\n",
        "\n",
        "            loss = loss_fnc(Yhat, Y)\n",
        "            loss.backward()\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "            optimizer.step() # Updates the parameters\n",
        "\n",
        "            #Accuracy computation\n",
        "            mask    = (Y != pad_index)\n",
        "            Yargmax = torch.argmax(Yhat,dim=1)\n",
        "            correct = torch.sum((Yargmax == Y) * mask)\n",
        "            total   = torch.sum(mask)\n",
        "            batch_accuracies.append(float(correct)/float(total))\n",
        "\n",
        "          if self.verbose:\n",
        "            print(f\"\\nEND OF EPOCH {epoch}\")\n",
        "            print(f\"[train] mean Loss = {sum(epoch_loss) / len(epoch_loss):.6f} | mean accurracy = {sum(batch_accuracies) / len(batch_accuracies):.6f}\")\n",
        "\n",
        "          # Evaluation\n",
        "          # This will automatically save the model with minimum loss\n",
        "          valid_loss, valid_accuracy = self.validate(validgenerator,\n",
        "                                                     batch_size, \n",
        "                                                     device=device,\n",
        "                                                     save_min_model=True)\n",
        "          \n",
        "          # Early stopping\n",
        "          if self.early_stopping(valid_loss, valid_accuracy):\n",
        "            return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "        # The train function returns the best dev accuracy \n",
        "        # and the number of epochs it trained for.\n",
        "        return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cpu',save_min_model=False):\n",
        "\n",
        "          self.training = False # Tells PyTorch we are in evaluation/inference mode (so dropout is deactivated).\n",
        "          \n",
        "          batch_accuracies = []\n",
        "          wrongs = []\n",
        "          gold_is = []\n",
        "          batch_losses      = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY) in datagenerator.generate_batches(batch_size):\n",
        "                with torch.no_grad():   \n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device).view(-1)\n",
        "                \n",
        "                  Yhat = self.forward(X)\n",
        "                  num_inputs, seq_length, _ = Yhat.shape\n",
        "                  Yhat = Yhat.view(num_inputs*seq_length, -1)\n",
        "\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask    = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  wrong = torch.sum((Yargmax != Y) * mask)\n",
        "                  gold_i = torch.sum(Y==datagenerator.output_sym2idx['I'])\n",
        "                  gold_is.append(gold_i)\n",
        "                  total   = torch.sum(mask)\n",
        "                  batch_accuracies.append(float(correct)/float(total))\n",
        "                  wrongs.append(wrong)\n",
        "\n",
        "          L = len(batch_losses)                  \n",
        "          valid_loss = sum(batch_losses)/L\n",
        "          valid_accuracy = sum(batch_accuracies)/L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "          if self.verbose:\n",
        "            print('[valid] mean Loss = %f | mean accurracy = %f'%(valid_loss,valid_accuracy))\n",
        "            #print(f'wrongs : {sum(wrongs)}\\n I tags: {sum(gold_is)}')\n",
        "\n",
        "          return valid_loss, valid_accuracy # used for early stopping in train"
      ],
      "metadata": {
        "id": "MRDC2F7qCHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "0M0OUgMzm--D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 64\n",
        "hidden_size = 128\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "trainset = DataGenerator(train)\n",
        "validset = DataGenerator(dev,parentgenerator=trainset)\n",
        "testset = DataGenerator(test,parentgenerator=trainset)\n",
        "tagger   = NERtagger(trainset,embed_size,hidden_size,bidirectional=True,device='cuda',patience=7)\n",
        "tagger.train(trainset,validset,epochs,batch_size,device='cuda') \n",
        "tagger.validate(testset,batch_size,device='cuda')\n",
        "\n",
        "p, r, f = tagger.evaluate(testset)\n",
        "print(f'precision: {p}, recall: {r}, f1: {f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNjN1-mpSUe6",
        "outputId": "4f4bd830-f80c-4074-d28c-68b6c0d12777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "END OF EPOCH 0\n",
            "[train] mean Loss = 0.974677 | mean accurracy = 0.709328\n",
            "[valid] mean Loss = 0.855888 | mean accurracy = 0.605528\n",
            "\n",
            "END OF EPOCH 1\n",
            "[train] mean Loss = 0.541308 | mean accurracy = 0.827558\n",
            "[valid] mean Loss = 1.397289 | mean accurracy = 0.606834\n",
            "\n",
            "END OF EPOCH 2\n",
            "[train] mean Loss = 0.410139 | mean accurracy = 0.829120\n",
            "[valid] mean Loss = 1.026457 | mean accurracy = 0.606834\n",
            "\n",
            "END OF EPOCH 3\n",
            "[train] mean Loss = 0.291146 | mean accurracy = 0.828809\n",
            "[valid] mean Loss = 0.464194 | mean accurracy = 0.606916\n",
            "\n",
            "END OF EPOCH 4\n",
            "[train] mean Loss = 0.252387 | mean accurracy = 0.867933\n",
            "[valid] mean Loss = 0.383736 | mean accurracy = 0.989495\n",
            "\n",
            "END OF EPOCH 5\n",
            "[train] mean Loss = 0.221011 | mean accurracy = 0.979195\n",
            "[valid] mean Loss = 0.282479 | mean accurracy = 0.988140\n",
            "\n",
            "END OF EPOCH 6\n",
            "[train] mean Loss = 0.173502 | mean accurracy = 0.976362\n",
            "[valid] mean Loss = 0.127033 | mean accurracy = 0.983771\n",
            "\n",
            "END OF EPOCH 7\n",
            "[train] mean Loss = 0.133710 | mean accurracy = 0.966672\n",
            "[valid] mean Loss = 0.094434 | mean accurracy = 0.984577\n",
            "\n",
            "END OF EPOCH 8\n",
            "[train] mean Loss = 0.109412 | mean accurracy = 0.971438\n",
            "[valid] mean Loss = 0.086996 | mean accurracy = 0.988803\n",
            "\n",
            "END OF EPOCH 9\n",
            "[train] mean Loss = 0.093440 | mean accurracy = 0.981397\n",
            "[valid] mean Loss = 0.789386 | mean accurracy = 0.809031\n",
            "\n",
            "END OF EPOCH 10\n",
            "[train] mean Loss = 0.083708 | mean accurracy = 0.981706\n",
            "[valid] mean Loss = 0.779186 | mean accurracy = 0.808963\n",
            "\n",
            "END OF EPOCH 11\n",
            "[train] mean Loss = 0.075892 | mean accurracy = 0.982622\n",
            "[valid] mean Loss = 0.734274 | mean accurracy = 0.830085\n",
            "\n",
            "END OF EPOCH 12\n",
            "[train] mean Loss = 0.071420 | mean accurracy = 0.983466\n",
            "[valid] mean Loss = 0.518370 | mean accurracy = 0.877982\n",
            "\n",
            "END OF EPOCH 13\n",
            "[train] mean Loss = 0.068053 | mean accurracy = 0.983640\n",
            "[valid] mean Loss = 0.123562 | mean accurracy = 0.973326\n",
            "\n",
            "END OF EPOCH 14\n",
            "[train] mean Loss = 0.065279 | mean accurracy = 0.983815\n",
            "[valid] mean Loss = 0.050029 | mean accurracy = 0.989234\n",
            "\n",
            "END OF EPOCH 15\n",
            "[train] mean Loss = 0.062495 | mean accurracy = 0.985321\n",
            "[valid] mean Loss = 0.049277 | mean accurracy = 0.989816\n",
            "\n",
            "END OF EPOCH 16\n",
            "[train] mean Loss = 0.059470 | mean accurracy = 0.986512\n",
            "[valid] mean Loss = 0.651334 | mean accurracy = 0.824478\n",
            "\n",
            "END OF EPOCH 17\n",
            "[train] mean Loss = 0.056378 | mean accurracy = 0.986946\n",
            "[valid] mean Loss = 0.577962 | mean accurracy = 0.830154\n",
            "\n",
            "END OF EPOCH 18\n",
            "[train] mean Loss = 0.053878 | mean accurracy = 0.986714\n",
            "[valid] mean Loss = 0.466541 | mean accurracy = 0.868923\n",
            "\n",
            "END OF EPOCH 19\n",
            "[train] mean Loss = 0.051532 | mean accurracy = 0.986926\n",
            "[valid] mean Loss = 0.045270 | mean accurracy = 0.989884\n",
            "\n",
            "END OF EPOCH 20\n",
            "[train] mean Loss = 0.049349 | mean accurracy = 0.987262\n",
            "[valid] mean Loss = 0.500078 | mean accurracy = 0.845087\n",
            "\n",
            "END OF EPOCH 21\n",
            "[train] mean Loss = 0.046866 | mean accurracy = 0.987903\n",
            "[valid] mean Loss = 0.453439 | mean accurracy = 0.850120\n",
            "\n",
            "END OF EPOCH 22\n",
            "[train] mean Loss = 0.044270 | mean accurracy = 0.987788\n",
            "[valid] mean Loss = 0.461350 | mean accurracy = 0.840205\n",
            "\n",
            "END OF EPOCH 23\n",
            "[train] mean Loss = 0.041937 | mean accurracy = 0.988168\n",
            "[valid] mean Loss = 0.424189 | mean accurracy = 0.863904\n",
            "\n",
            "END OF EPOCH 24\n",
            "[train] mean Loss = 0.039439 | mean accurracy = 0.988621\n",
            "[valid] mean Loss = 0.375543 | mean accurracy = 0.878058\n",
            "\n",
            "END OF EPOCH 25\n",
            "[train] mean Loss = 0.037015 | mean accurracy = 0.988673\n",
            "[valid] mean Loss = 0.389789 | mean accurracy = 0.869198\n",
            "\n",
            "END OF EPOCH 26\n",
            "[train] mean Loss = 0.034681 | mean accurracy = 0.989526\n",
            "[valid] mean Loss = 0.038293 | mean accurracy = 0.990746\n",
            "\n",
            "END OF EPOCH 27\n",
            "[train] mean Loss = 0.032665 | mean accurracy = 0.989681\n",
            "[valid] mean Loss = 0.037686 | mean accurracy = 0.990972\n",
            "\n",
            "END OF EPOCH 28\n",
            "[train] mean Loss = 0.030728 | mean accurracy = 0.990282\n",
            "[valid] mean Loss = 0.037521 | mean accurracy = 0.991027\n",
            "\n",
            "END OF EPOCH 29\n",
            "[train] mean Loss = 0.028343 | mean accurracy = 0.991096\n",
            "[valid] mean Loss = 0.038082 | mean accurracy = 0.990958\n",
            "\n",
            "END OF EPOCH 30\n",
            "[train] mean Loss = 0.025983 | mean accurracy = 0.992066\n",
            "[valid] mean Loss = 0.038370 | mean accurracy = 0.991040\n",
            "\n",
            "END OF EPOCH 31\n",
            "[train] mean Loss = 0.024061 | mean accurracy = 0.992961\n",
            "[valid] mean Loss = 0.037628 | mean accurracy = 0.990740\n",
            "\n",
            "END OF EPOCH 32\n",
            "[train] mean Loss = 0.022672 | mean accurracy = 0.993202\n",
            "[valid] mean Loss = 0.161329 | mean accurracy = 0.952392\n",
            "\n",
            "END OF EPOCH 33\n",
            "[train] mean Loss = 0.021030 | mean accurracy = 0.994079\n",
            "[valid] mean Loss = 0.035681 | mean accurracy = 0.990123\n",
            "\n",
            "END OF EPOCH 34\n",
            "[train] mean Loss = 0.020143 | mean accurracy = 0.994310\n",
            "[valid] mean Loss = 0.035490 | mean accurracy = 0.990096\n",
            "\n",
            "END OF EPOCH 35\n",
            "[train] mean Loss = 0.020044 | mean accurracy = 0.993984\n",
            "[valid] mean Loss = 0.256694 | mean accurracy = 0.925952\n",
            "\n",
            "END OF EPOCH 36\n",
            "[train] mean Loss = 0.017086 | mean accurracy = 0.995372\n",
            "[valid] mean Loss = 0.315174 | mean accurracy = 0.903458\n",
            "\n",
            "END OF EPOCH 37\n",
            "[train] mean Loss = 0.015695 | mean accurracy = 0.995802\n",
            "[valid] mean Loss = 0.036311 | mean accurracy = 0.990260\n",
            "\n",
            "END OF EPOCH 38\n",
            "[train] mean Loss = 0.015086 | mean accurracy = 0.996043\n",
            "[valid] mean Loss = 0.214544 | mean accurracy = 0.945837\n",
            "\n",
            "END OF EPOCH 39\n",
            "[train] mean Loss = 0.012972 | mean accurracy = 0.997061\n",
            "[valid] mean Loss = 0.412092 | mean accurracy = 0.890816\n",
            "\n",
            "END OF EPOCH 40\n",
            "[train] mean Loss = 0.011871 | mean accurracy = 0.997286\n",
            "[valid] mean Loss = 0.296829 | mean accurracy = 0.915224\n",
            "\n",
            "END OF EPOCH 41\n",
            "[train] mean Loss = 0.010952 | mean accurracy = 0.997679\n",
            "[valid] mean Loss = 0.379319 | mean accurracy = 0.886591\n",
            "\n",
            "EARLY STOP\n",
            "\n",
            "[valid] mean Loss = 0.418420 | mean accurracy = 0.873457\n",
            "precision: 0.9924792051315308, recall: 0.6508719325065613, f1: 0.786170244216919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics on the data"
      ],
      "metadata": {
        "id": "SbJ6gimvnIYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent class baseline (accuracy)\n",
        "test['tags'].apply(lambda x: x.count('O')/len(x)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc3A_gUrLujG",
        "outputId": "3b51792c-fe16-4218-8f56-191bdfa446f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9850698504758424"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision baseline\n",
        "test['tags'].apply(lambda x: (x.count('I') + x.count('B'))/len(x)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDl9kkeV1XgN",
        "outputId": "40611478-2eed-4332-dc8c-f83bacf65235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0149301495241576"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}
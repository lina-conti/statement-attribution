{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the data \n",
        "\n"
      ],
      "metadata": {
        "id": "MKN6krDPmyhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import re \n",
        "\n",
        "URL = 'https://drive.google.com/file/d/1-6E4h5lH2AHRUBVJUtchXSggMRYr_-8F/view?usp=share_link'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
        "\n",
        "df_speaker = pd.read_csv(path).dropna()\n",
        "df_speaker = df_speaker.drop_duplicates('text')\n",
        "df_speaker"
      ],
      "metadata": {
        "id": "M9LL1mr7mwgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fa15482d-b5c7-420c-8052-e1cbb865cd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                       speaker  \\\n",
              "0             0             Roselyne Bachelot   \n",
              "1             1                          None   \n",
              "2             2             Roselyne Bachelot   \n",
              "3             3                          None   \n",
              "4             4             Roselyne Bachelot   \n",
              "..          ...                           ...   \n",
              "785         126  Marjolaine Meynier-Millefert   \n",
              "786         127                          None   \n",
              "787         128                          None   \n",
              "788         129                          None   \n",
              "789         130                          None   \n",
              "\n",
              "                                                  text  \n",
              "0    Roselyne Bachelot en campagne à Angoulême : \" ...  \n",
              "1    C'est un métier et à ce jeu, elle a quelques k...  \n",
              "2    * Roselyne Bachelot en campagne à Angoulême : ...  \n",
              "3    \\n\\nC 'est un métier et à ce jeu, elle a quelq...  \n",
              "4    \\n\\n* La graine de l'expérience *\\n\\nUn style ...  \n",
              "..                                                 ...  \n",
              "785  \\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...  \n",
              "786  \\n\\nHabituellement, le samedi matin est un mom...  \n",
              "787  Présidentielle : à Beauvais, le ministre Franc...  \n",
              "788  Le ministre du Commerce extérieur et de l'Attr...  \n",
              "789  Par Patrick Caffin\\n\\nPour les soutiens d'Emma...  \n",
              "\n",
              "[790 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c08d6c0-3167-4a1a-b296-244c37e5dda1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>Roselyne Bachelot en campagne à Angoulême : \" ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>C'est un métier et à ce jeu, elle a quelques k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>* Roselyne Bachelot en campagne à Angoulême : ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nC 'est un métier et à ce jeu, elle a quelq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>\\n\\n* La graine de l'expérience *\\n\\nUn style ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785</th>\n",
              "      <td>126</td>\n",
              "      <td>Marjolaine Meynier-Millefert</td>\n",
              "      <td>\\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>127</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nHabituellement, le samedi matin est un mom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>128</td>\n",
              "      <td>None</td>\n",
              "      <td>Présidentielle : à Beauvais, le ministre Franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>129</td>\n",
              "      <td>None</td>\n",
              "      <td>Le ministre du Commerce extérieur et de l'Attr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>130</td>\n",
              "      <td>None</td>\n",
              "      <td>Par Patrick Caffin\\n\\nPour les soutiens d'Emma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>790 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c08d6c0-3167-4a1a-b296-244c37e5dda1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c08d6c0-3167-4a1a-b296-244c37e5dda1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c08d6c0-3167-4a1a-b296-244c37e5dda1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: preprocessing \n",
        "\n",
        "- train test split \n",
        "\n"
      ],
      "metadata": {
        "id": "-EKzlK_Fm8F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "\n",
        "from polyglot.text import Text\n",
        "from polyglot.detect.base import logger as polyglot_logger\n",
        "polyglot_logger.setLevel(\"ERROR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1wVlfDFwfgn",
        "outputId": "22b18cdc-d305-4d5e-fb66-1604add962ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: polyglot in /usr/local/lib/python3.8/dist-packages (16.7.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.8/dist-packages (2.10.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.8/dist-packages (0.41)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.8/dist-packages (2.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizeing and aligning tags for speaker data \n",
        "df_speaker['tags'] = df_speaker[['speaker', 'text']].apply(lambda x: ['I' if word in set(re.findall('[\\w]+',x.speaker)) else 'O' for word in Text(x.text).words], axis=1 )\n",
        "df_speaker['tokenized_text'] = df_speaker['text'].apply(lambda x: Text(x).words)\n",
        "df_speaker = df_speaker[df_speaker.tokenized_text.apply(lambda x: len(x) < 200)]\n",
        "\n",
        "df_speaker.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "o7N9uMSoyng2",
        "outputId": "c8a1655b-b6e7-4e4e-c9d7-0b2a55b5f02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                               speaker  \\\n",
              "0           0                     Roselyne Bachelot   \n",
              "1           1                                  None   \n",
              "2           2                     Roselyne Bachelot   \n",
              "4           4                     Roselyne Bachelot   \n",
              "5           5  Roselyne Bachelot, Stanislas Guerini   \n",
              "\n",
              "                                                text  \\\n",
              "0  Roselyne Bachelot en campagne à Angoulême : \" ...   \n",
              "1  C'est un métier et à ce jeu, elle a quelques k...   \n",
              "2  * Roselyne Bachelot en campagne à Angoulême : ...   \n",
              "4  \\n\\n* La graine de l'expérience *\\n\\nUn style ...   \n",
              "5  \\n\\nLa politique étrangère, justement. Une béq...   \n",
              "\n",
              "                                                tags  \\\n",
              "0            [I, I, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2  [O, I, I, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "5  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [Roselyne, Bachelot, en, campagne, à, Angoulêm...  \n",
              "1  [C'est, un, métier, et, à, ce, jeu, ,, elle, a...  \n",
              "2  [*, Roselyne, Bachelot, en, campagne, à, Angou...  \n",
              "4  [*, La, graine, de, l'expérience, *, Un, style...  \n",
              "5  [La, politique, étrangère, ,, justement, ., Un...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8194f6e-ca86-4f0d-afce-87911cb085b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>Roselyne Bachelot en campagne à Angoulême : \" ...</td>\n",
              "      <td>[I, I, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Roselyne, Bachelot, en, campagne, à, Angoulêm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>C'est un métier et à ce jeu, elle a quelques k...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[C'est, un, métier, et, à, ce, jeu, ,, elle, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>* Roselyne Bachelot en campagne à Angoulême : ...</td>\n",
              "      <td>[O, I, I, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[*, Roselyne, Bachelot, en, campagne, à, Angou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>\\n\\n* La graine de l'expérience *\\n\\nUn style ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[*, La, graine, de, l'expérience, *, Un, style...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Roselyne Bachelot, Stanislas Guerini</td>\n",
              "      <td>\\n\\nLa politique étrangère, justement. Une béq...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[La, politique, étrangère, ,, justement, ., Un...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8194f6e-ca86-4f0d-afce-87911cb085b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8194f6e-ca86-4f0d-afce-87911cb085b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8194f6e-ca86-4f0d-afce-87911cb085b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle \n",
        "df_speaker = df_speaker.sample(frac=1)\n",
        "\n",
        "#train test split \n",
        "test_length  = int(df_speaker.shape[0] * 0.15)\n",
        "\n",
        "test_speaker         = df_speaker[:test_length]\n",
        "dev_speaker         = df_speaker[test_length:2*test_length]\n",
        "train_speaker       = df_speaker[2*test_length:]\n",
        "\n",
        "print(train_speaker.shape)\n",
        "print(dev_speaker.shape)\n",
        "print(test_speaker.shape)"
      ],
      "metadata": {
        "id": "aWKC7uJPnVTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72a7dab-b8ae-41da-f7d4-6407fca26862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(482, 5)\n",
            "(103, 5)\n",
            "(103, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization and computation of input and output vocabulary"
      ],
      "metadata": {
        "id": "YNSb2R_Eqi3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making character vocabulary \n",
        "def vocabulary(df, input_vocab, padding='<pad>', unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token \n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "\n",
        "    if input_vocab:\n",
        "      sequences_list = df['tokenized_text'].to_list()\n",
        "    else:\n",
        "      sequences_list = df['tags'].to_list()\n",
        "\n",
        "    # Creates the mapping from ids to symbols (a list)\n",
        "    idx2sym = list({element.strip() for sequence in sequences_list for element in sequence})\n",
        "\n",
        "    # Decides whether to include the unknown token\n",
        "    if unknown:\n",
        "      idx2sym.append(unknown)\n",
        "\n",
        "    # Decides whether to include the padding token\n",
        "    if padding:\n",
        "      idx2sym.append(padding)\n",
        "\n",
        "    # Creates the mapping from symbols to ids (a dictionary)\n",
        "    sym2idx = {idx2sym[j]: j for j in range(len(idx2sym))}\n",
        "\n",
        "    # Return the two vocabulary maps idx2sym and sym2idx as a couple\n",
        "    return idx2sym, sym2idx   "
      ],
      "metadata": {
        "id": "YS335uhLsqaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "idx2sym, sym2idx  = vocabulary(df_speaker,True,padding=None,unknown=None)\n",
        "print(sym2idx)"
      ],
      "metadata": {
        "id": "kSvUVr8X0DVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding and decoding sequences "
      ],
      "metadata": {
        "id": "EeEQSmEq3Vs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens to match pad_size if needed\n",
        "    return [sequence[i] if i<len(sequence) else pad_token for i in range(pad_size)]\n",
        "   \n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    return [coding_map[symbol] if symbol in coding_map else coding_map[unk_token] for symbol in sequence]\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings \n",
        "    return [decoding_map[id] for id in sequence]"
      ],
      "metadata": {
        "id": "Tyz_WtyS3VJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing NER data from WiNER french NER repository "
      ],
      "metadata": {
        "id": "dRYpwvMZfsev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/YoannDupont/WiNER-fr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E4h6gND2wQ9",
        "outputId": "e73b9d01-2cb5-4cb3-d6a1-63fcf99cc37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WiNER-fr'...\n",
            "remote: Enumerating objects: 2981, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 2981 (delta 0), reused 3 (delta 0), pack-reused 2945\u001b[K\n",
            "Receiving objects: 100% (2981/2981), 1.46 MiB | 1.54 MiB/s, done.\n",
            "Resolving deltas: 100% (450/450), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob \n",
        "\n",
        "ann_files = (list(sorted(glob.glob('/content/WiNER-fr/201*/*/*.ann'))))\n",
        "txt_files = (list(sorted(glob.glob('/content/WiNER-fr/201*/*/*.txt'))))\n",
        "\n",
        "len(txt_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTjChKA2QBwC",
        "outputId": "17fd64cc-119f-4da3-9b0c-4861722e4ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1191"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aligning brat labels with our tokenization \n",
        "\n",
        "def align_brat_on_tokens(txtfile, annfile): \n",
        "  with open(txtfile, 'r') as txtfile: \n",
        "    spans = [(int(line.split()[2]), int(line.split()[3]), line.split()[1]) for line in open(annfile, 'r').readlines()]\n",
        "    doc = txtfile.read()\n",
        "    char_ind = 0 \n",
        "    chunks = []\n",
        "    tags = []\n",
        "    #first segment the named entities away from the rest of the text \n",
        "    for start, end, kind in spans: \n",
        "      if char_ind < start: \n",
        "        chunks += [doc[char_ind:start]]\n",
        "        tags += 'O'\n",
        "        char_ind = start\n",
        "      chunks += [doc[start:end]]\n",
        "      tags += ('B' if (kind=='Person' and tags and tags[-1]=='I')\n",
        "                  else 'I' if kind == 'Person' \n",
        "                  else 'O')\n",
        "      char_ind = end\n",
        "    #then tokanize and align tags \n",
        "    new_tags = []\n",
        "    tokens =[]\n",
        "    for i, chunk in enumerate(chunks): \n",
        "      tokenized = Text(chunk).words\n",
        "      tokens+=tokenized\n",
        "      #print(tags[i])\n",
        "      new_tags += [tags[i]]+['I']*(len(tokenized)-1) if tags[i]=='B' else  tags[i]*len(tokenized) \n",
        "    #print()\n",
        "  return tokens, new_tags"
      ],
      "metadata": {
        "id": "jRlrgDbjfqD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def examples_from_brat(txt_files, ann_files):\n",
        "  \"\"\"\n",
        "  txt_files: list of strings (paths to .txt files)\n",
        "  ann_files: list of strings (paths to .ann files)\n",
        "  IMPORTANT: it is assumed that the .txt and .ann files are in the same order \n",
        "  Returns a DataFrame with columns 'tokenized_text' and 'tags', with one row for each example.\n",
        "  \"\"\"\n",
        "\n",
        "  tokenss = []\n",
        "  tagss = []\n",
        "\n",
        "  for i in range(len(txt_files)):\n",
        "    tokens, tags = align_brat_on_tokens(txt_files[i], ann_files[i])\n",
        "    assert len(tokens) == len(tags)\n",
        "\n",
        "    if len(tokens) < 100:\n",
        "      tokenss.append(tokens)\n",
        "      tagss.append(tags)\n",
        "\n",
        "    else:\n",
        "      for j in range(int(len(tokens)/100)):\n",
        "        start = j*100\n",
        "        tokenss.append(tokens[start:start+100])\n",
        "        tagss.append(tags[start:start+100])\n",
        "\n",
        "      start = (j+1)*100\n",
        "      tokenss.append(tokens[start:len(tokens)])\n",
        "      tagss.append(tags[start:len(tokens)])\n",
        "\n",
        "  return(pd.DataFrame({'tokenized_text': tokenss, 'tags': tagss}))"
      ],
      "metadata": {
        "id": "Y1kS-ki1QHAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_NER = examples_from_brat(txt_files, ann_files)\n",
        "\n",
        "#we filter out sequences that are less than 5 tokens long \n",
        "df_NER = df_NER[df_NER.tokenized_text.apply(lambda x: len(x) > 5)]"
      ],
      "metadata": {
        "id": "zJvKnsm3QIz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle\n",
        "df_NER = df_NER.sample(frac=1)\n",
        "\n",
        "#train test split \n",
        "test_length  = int(df_NER.shape[0] * 0.10)\n",
        "\n",
        "test_NER         = df_NER[:test_length]\n",
        "dev_NER          = df_NER[test_length:2*test_length]\n",
        "train_NER        = df_NER[2*test_length:]\n",
        "\n",
        "print(train_NER.shape)\n",
        "print(dev_NER.shape)\n",
        "print(test_NER.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZwwAxfpS5PJ",
        "outputId": "67aa79a1-4cc6-4b36-ef78-ac8df52084b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2792, 2)\n",
            "(349, 2)\n",
            "(349, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader (Batch Generator)"
      ],
      "metadata": {
        "id": "c0yxrmY5nWE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "class DataGenerator:\n",
        "\n",
        "        def __init__(self, df, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx \n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym \n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx \n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym  \n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  # Creates 4 encoding maps from datafile \n",
        "                  self.input_idx2sym, self.input_sym2idx  = vocabulary(df, \n",
        "                                                                       input_vocab=True)\n",
        "                  self.output_idx2sym,self.output_sym2idx = vocabulary(df, \n",
        "                                                                       input_vocab=False,\n",
        "                                                                       padding=None)\n",
        "\n",
        "              # Stores the dataset with sentence structure (a list of lists of strings) in the following fields \n",
        "              self.Xtokens = df['tokenized_text'].to_list()\n",
        "              self.Ytokens = df['tags'].to_list()\n",
        "      \n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #Batches are lists of lists\n",
        "              \n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "              \n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #If we don't shuffle the train set after each epoch, the model may not converge\n",
        "              shuffle(idxes)\n",
        "              #For efficiency reasons, it is nice to have batches with a similar nb of elements,\n",
        "              #so we don't do useless computations over the padding token\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend] \n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)              \n",
        "              \n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx], batch_len, self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx,unk_token=self.unk_token) for seq in seqY]\n",
        "                 \n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ],
      "metadata": {
        "id": "HZXHCrZM2xYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_df = pd.concat([df_NER, df_speaker])\n",
        "\n",
        "grandparent_loader = DataGenerator(all_train_df)"
      ],
      "metadata": {
        "id": "yPfV5DWdWixl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model \n",
        "- LSTM encoding of paragraphs \n",
        "- BIO tagging of sequences "
      ],
      "metadata": {
        "id": "vFVUtZQiniWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    \n",
        "    def __init__(self, patience=7, verbose=True):\n",
        "        \"\"\"\n",
        "        patience (int): How long to wait after last time validation loss improved.\n",
        "                        Default: 7    \n",
        "        verbose (bool): Whether to print a message when early stop is activated.\n",
        "                        Default: True       \n",
        "        \"\"\"\n",
        "        self.patience       = patience\n",
        "        self.counter        = 0         # number of epochs since last improvement\n",
        "        self.best_loss      = None\n",
        "        self.best_accuracy  = None\n",
        "        self.verbose        = verbose\n",
        "\n",
        "    def __call__(self, val_loss, val_accuracy):\n",
        "        \"\"\"\n",
        "        val_loss (float): Validation loss obtained in the current epoch\n",
        "        val_accuracy (float): Validation accuracy obtained in the current epoch (used only for information, early stopping is based on loss)\n",
        "        \"\"\"\n",
        "        if self.best_loss is None:  # if first iteration\n",
        "            self.best_loss      = val_loss\n",
        "            self.best_accuracy  = val_accuracy\n",
        "\n",
        "        if val_loss < self.best_loss: # if improvement\n",
        "            self.best_loss      = val_loss\n",
        "            self.counter        = 0\n",
        "\n",
        "        if val_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy  = val_accuracy  # just for information\n",
        "\n",
        "        if val_loss > self.best_loss: # if no improvement\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "              if self.verbose:\n",
        "                print(\"\\nEARLY STOP\\n\")\n",
        "              self._reset()\n",
        "              return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _reset(self): \n",
        "      self.counter = 0 \n",
        "      self.best_loss = None\n",
        "      self.best_accuracy = None"
      ],
      "metadata": {
        "id": "nUyOCNf1ne_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core part\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator,embedding_size,hidden_size,device='cpu',\n",
        "                   patience=7,bidirectional=True,verbose=True):\n",
        "        super(NERtagger, self).__init__()        \n",
        "        self.embedding_size    = embedding_size\n",
        "        self.hidden_size       = hidden_size\n",
        "        self.bidirectional     = bidirectional  # whether the lstm is bidirectional or not\n",
        "        self.verbose           = verbose\n",
        "        self.allocate_params(traingenerator,device) \n",
        "        self.early_stopping    = EarlyStopping(verbose=verbose,patience=patience)\n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device):\n",
        "        # Creates fields for nn Layers\n",
        "\n",
        "        invocab_size   = len(datagenerator.input_idx2sym)\n",
        "        pad_idx        = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "        outvocab_size  = len(datagenerator.output_idx2sym)\n",
        "        \n",
        "        self.embeddings = nn.Embedding(invocab_size,\n",
        "                                      self.embedding_size,\n",
        "                                      padding_idx=pad_idx).to(device)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
        "                            hidden_size=self.hidden_size,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=self.bidirectional).to(device) \n",
        "                            # batch_first so it takes input of shape (batch, seq, feature)\n",
        "        \n",
        "        size_X         = self.hidden_size*2 if self.bidirectional else self.hidden_size # this line is necessary so the bidirectional switch works\n",
        "        self.output    = nn.Linear(size_X,outvocab_size).to(device)\n",
        " \n",
        "\n",
        "      def forward(self,X):\n",
        "        # X is of shape batch_size x sequence_length\n",
        "\n",
        "        # Prediction steps:\n",
        "        # embedded_X of shape batch_size x sequence_length x embedding_size\n",
        "        embedded_X  = self.embeddings(X)\n",
        "\n",
        "        # lstm_encodings of shape batch_size x sequence_length x lstm_hidden_size\n",
        "        lstm_encodings, (_, _) = self.lstm(embedded_X) \n",
        "\n",
        "        # output of shape batch_size x outvocab_size\n",
        "        return self.output(lstm_encodings) \n",
        "\n",
        "\n",
        "      def evaluate(self, datagenerator, batch_size = 64, device = 'cpu'): \n",
        "        '''evaluates the performance of the model on a test set. \n",
        "        calculates recall and precision, considering 'O' tags to be the negative case \n",
        "        and all i tags to be positice cases '''\n",
        "        self.to(device)\n",
        "        #self.eval()\n",
        "        true_neg = 0 \n",
        "        true_pos = 0 \n",
        "        false_neg = 0 \n",
        "        false_pos = 0 \n",
        "        pad_idx   = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "\n",
        "        for batch_x, batch_y in datagenerator.generate_batches(batch_size): \n",
        "          with torch.no_grad():\n",
        "            X_in    = torch.tensor(batch_x).to(device) #batch_size x seq_length\n",
        "            y_gold  = torch.tensor(batch_y).to(device) #batch_size x seq_length\n",
        "            y_gold  = y_gold.view(-1) #batch_size*seq_length\n",
        "\n",
        "            #make predictions:\n",
        "            Yhat    = self.forward(X_in) #batch_size x seq_length x outvocab size \n",
        "            y_pred = torch.argmax(Yhat, dim = 2) #batch_size x seq_length x 1\n",
        "            y_pred = y_pred.view(-1)\n",
        "\n",
        "            pad_mask   = (y_gold != pad_idx)\n",
        "            pos_mask   = (y_pred != datagenerator.output_sym2idx['O'])\n",
        "            neg_mask   = (y_pred == datagenerator.output_sym2idx['O'])\n",
        "\n",
        "            true_pos  += torch.sum((y_pred==y_gold)*pos_mask*pad_mask)\n",
        "            true_neg  += torch.sum((y_pred == y_gold)*neg_mask*pad_mask)\n",
        "            false_pos += torch.sum((y_pred != y_gold)*pos_mask*pad_mask)\n",
        "            false_neg += torch.sum((y_pred != y_gold)*neg_mask*pad_mask)\n",
        "\n",
        "        precision = true_pos/(true_pos+false_pos)\n",
        "        recall    = true_pos/(true_pos+false_neg)\n",
        "        f_score   = 2*((precision*recall)/(precision+recall))\n",
        "        return precision, recall, f_score \n",
        "\n",
        "        \n",
        "      def train(self,traingenerator,validgenerator,epochs,batch_size,device='cpu'): \n",
        "\n",
        "        self.minloss = 10000000 # the min loss found so far on validation data\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        \n",
        "        device    = torch.device(device)\n",
        "        pad_index = traingenerator.input_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "          self.training = True  # Tells PyTorch we are in training mode (so dropout is activated).\n",
        "\n",
        "          epoch_loss = []\n",
        "          batch_accuracies = []\n",
        "          for seqX,seqY in traingenerator.generate_batches(batch_size):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            X = torch.LongTensor(seqX).to(device)\n",
        "            # Y is of shape batch_size x seq_length\n",
        "            Y = torch.LongTensor(seqY).to(device).view(-1)\n",
        "\n",
        "            # Yhat is of shape batch_size x seq_length x nb_classes\n",
        "            Yhat = self.forward(X)\n",
        "            num_inputs, seq_length, _ = Yhat.shape\n",
        "            Yhat = Yhat.view(num_inputs*seq_length, -1)\n",
        "\n",
        "            loss = loss_fnc(Yhat, Y)\n",
        "            loss.backward()\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "            optimizer.step() # Updates the parameters\n",
        "\n",
        "            #Accuracy computation\n",
        "            mask    = (Y != pad_index)\n",
        "            Yargmax = torch.argmax(Yhat,dim=1)\n",
        "            correct = torch.sum((Yargmax == Y) * mask)\n",
        "            total   = torch.sum(mask)\n",
        "            batch_accuracies.append(float(correct)/float(total))\n",
        "\n",
        "          if self.verbose:\n",
        "            print(f\"\\nEND OF EPOCH {epoch}\")\n",
        "            print(f\"[train] mean Loss = {sum(epoch_loss) / len(epoch_loss):.6f} | mean accurracy = {sum(batch_accuracies) / len(batch_accuracies):.6f}\")\n",
        "\n",
        "          # Evaluation\n",
        "          # This will automatically save the model with minimum loss\n",
        "          valid_loss, valid_accuracy = self.validate(validgenerator,\n",
        "                                                     batch_size, \n",
        "                                                     device=device,\n",
        "                                                     save_min_model=True)\n",
        "          \n",
        "          # Early stopping\n",
        "          if self.early_stopping(valid_loss, valid_accuracy):\n",
        "            return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "        # The train function returns the best dev accuracy \n",
        "        # and the number of epochs it trained for.\n",
        "        return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cpu',save_min_model=False):\n",
        "\n",
        "          self.training = False # Tells PyTorch we are in evaluation/inference mode (so dropout is deactivated).\n",
        "          \n",
        "          batch_accuracies = []\n",
        "          wrongs = []\n",
        "          gold_is = []\n",
        "          batch_losses      = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY) in datagenerator.generate_batches(batch_size):\n",
        "                with torch.no_grad():   \n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device).view(-1)\n",
        "                \n",
        "                  Yhat = self.forward(X)\n",
        "                  num_inputs, seq_length, _ = Yhat.shape\n",
        "                  Yhat = Yhat.view(num_inputs*seq_length, -1)\n",
        "\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask    = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  wrong = torch.sum((Yargmax != Y) * mask)\n",
        "                  gold_i = torch.sum(Y==datagenerator.output_sym2idx['I'])\n",
        "                  gold_is.append(gold_i)\n",
        "                  total   = torch.sum(mask)\n",
        "                  batch_accuracies.append(float(correct)/float(total))\n",
        "                  wrongs.append(wrong)\n",
        "\n",
        "          L = len(batch_losses)                  \n",
        "          valid_loss = sum(batch_losses)/L\n",
        "          valid_accuracy = sum(batch_accuracies)/L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "          if self.verbose:\n",
        "            print('[valid] mean Loss = %f | mean accurracy = %f'%(valid_loss,valid_accuracy))\n",
        "            #print(f'wrongs : {sum(wrongs)}\\n I tags: {sum(gold_is)}')\n",
        "\n",
        "          return valid_loss, valid_accuracy # used for early stopping in train"
      ],
      "metadata": {
        "id": "MRDC2F7qCHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLAIN NER\n",
        "\n",
        "embed_size = 64\n",
        "hidden_size = 128\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "trainset = DataGenerator(train_NER,parentgenerator=grandparent_loader)\n",
        "validset = DataGenerator(dev_NER,parentgenerator=grandparent_loader)\n",
        "tagger   = NERtagger(trainset,embed_size,hidden_size,bidirectional=True,device='cuda',patience=5)\n",
        "tagger.train(trainset,validset,epochs,batch_size,device='cuda') \n",
        "\n",
        "p, r, f = tagger.evaluate(validset, device='cuda')\n",
        "print(f'precision: {p}, recall: {r}, f1: {f}')"
      ],
      "metadata": {
        "id": "shj-mysVKTDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00d985a-f5b2-4b51-e9e7-7b109dd67b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "END OF EPOCH 0\n",
            "[train] mean Loss = 0.447250 | mean accurracy = 0.925080\n",
            "[valid] mean Loss = 0.600456 | mean accurracy = 0.876249\n",
            "\n",
            "END OF EPOCH 1\n",
            "[train] mean Loss = 0.230421 | mean accurracy = 0.937995\n",
            "[valid] mean Loss = 0.562577 | mean accurracy = 0.877209\n",
            "\n",
            "END OF EPOCH 2\n",
            "[train] mean Loss = 0.186143 | mean accurracy = 0.937901\n",
            "[valid] mean Loss = 0.542741 | mean accurracy = 0.876335\n",
            "\n",
            "END OF EPOCH 3\n",
            "[train] mean Loss = 0.154037 | mean accurracy = 0.940049\n",
            "[valid] mean Loss = 0.468003 | mean accurracy = 0.883263\n",
            "\n",
            "END OF EPOCH 4\n",
            "[train] mean Loss = 0.119064 | mean accurracy = 0.956662\n",
            "[valid] mean Loss = 0.380719 | mean accurracy = 0.915817\n",
            "\n",
            "END OF EPOCH 5\n",
            "[train] mean Loss = 0.090411 | mean accurracy = 0.971784\n",
            "[valid] mean Loss = 0.314255 | mean accurracy = 0.933582\n",
            "\n",
            "END OF EPOCH 6\n",
            "[train] mean Loss = 0.069383 | mean accurracy = 0.977729\n",
            "[valid] mean Loss = 0.262234 | mean accurracy = 0.938919\n",
            "\n",
            "END OF EPOCH 7\n",
            "[train] mean Loss = 0.054381 | mean accurracy = 0.982958\n",
            "[valid] mean Loss = 0.248658 | mean accurracy = 0.940461\n",
            "\n",
            "END OF EPOCH 8\n",
            "[train] mean Loss = 0.043784 | mean accurracy = 0.986256\n",
            "[valid] mean Loss = 0.245405 | mean accurracy = 0.940013\n",
            "\n",
            "END OF EPOCH 9\n",
            "[train] mean Loss = 0.035573 | mean accurracy = 0.989468\n",
            "[valid] mean Loss = 0.239464 | mean accurracy = 0.941801\n",
            "\n",
            "END OF EPOCH 10\n",
            "[train] mean Loss = 0.029330 | mean accurracy = 0.991345\n",
            "[valid] mean Loss = 0.275387 | mean accurracy = 0.939402\n",
            "\n",
            "END OF EPOCH 11\n",
            "[train] mean Loss = 0.024051 | mean accurracy = 0.993201\n",
            "[valid] mean Loss = 0.236454 | mean accurracy = 0.940204\n",
            "\n",
            "END OF EPOCH 12\n",
            "[train] mean Loss = 0.020278 | mean accurracy = 0.994491\n",
            "[valid] mean Loss = 0.254891 | mean accurracy = 0.940351\n",
            "\n",
            "END OF EPOCH 13\n",
            "[train] mean Loss = 0.016516 | mean accurracy = 0.995631\n",
            "[valid] mean Loss = 0.259555 | mean accurracy = 0.940842\n",
            "\n",
            "END OF EPOCH 14\n",
            "[train] mean Loss = 0.013828 | mean accurracy = 0.996566\n",
            "[valid] mean Loss = 0.256649 | mean accurracy = 0.939343\n",
            "\n",
            "END OF EPOCH 15\n",
            "[train] mean Loss = 0.011480 | mean accurracy = 0.997280\n",
            "[valid] mean Loss = 0.272015 | mean accurracy = 0.940939\n",
            "\n",
            "END OF EPOCH 16\n",
            "[train] mean Loss = 0.009794 | mean accurracy = 0.997689\n",
            "[valid] mean Loss = 0.297030 | mean accurracy = 0.936519\n",
            "\n",
            "EARLY STOP\n",
            "\n",
            "precision: 0.8604651093482971, recall: 0.5680313110351562, f1: 0.6843155026435852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FINE TUNING\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "trainset = DataGenerator(train_speaker,parentgenerator=grandparent_loader)\n",
        "validset = DataGenerator(dev_speaker,parentgenerator=grandparent_loader)\n",
        "testset  = DataGenerator(test_speaker,parentgenerator=grandparent_loader)\n",
        "tagger.train(trainset,validset,epochs,batch_size,device='cuda') \n",
        "tagger.validate(testset, batch_size = 64, device = 'cuda')\n",
        "\n",
        "p, r, f = tagger.evaluate(testset, device='cuda')\n",
        "print(f'precision: {p}, recall: {r}, f1: {f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq7MEK6sTgF3",
        "outputId": "acf6e4c8-ea1c-40e1-fd59-41053301683f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "END OF EPOCH 0\n",
            "[train] mean Loss = 0.152316 | mean accurracy = 0.965370\n",
            "[valid] mean Loss = 0.061831 | mean accurracy = 0.989794\n",
            "\n",
            "END OF EPOCH 1\n",
            "[train] mean Loss = 0.088675 | mean accurracy = 0.980783\n",
            "[valid] mean Loss = 0.047394 | mean accurracy = 0.990142\n",
            "\n",
            "END OF EPOCH 2\n",
            "[train] mean Loss = 0.063773 | mean accurracy = 0.980198\n",
            "[valid] mean Loss = 0.039300 | mean accurracy = 0.987690\n",
            "\n",
            "END OF EPOCH 3\n",
            "[train] mean Loss = 0.055155 | mean accurracy = 0.981433\n",
            "[valid] mean Loss = 0.034806 | mean accurracy = 0.990352\n",
            "\n",
            "END OF EPOCH 4\n",
            "[train] mean Loss = 0.047722 | mean accurracy = 0.984995\n",
            "[valid] mean Loss = 0.032241 | mean accurracy = 0.991244\n",
            "\n",
            "END OF EPOCH 5\n",
            "[train] mean Loss = 0.042425 | mean accurracy = 0.987078\n",
            "[valid] mean Loss = 0.029950 | mean accurracy = 0.990965\n",
            "\n",
            "END OF EPOCH 6\n",
            "[train] mean Loss = 0.039014 | mean accurracy = 0.987534\n",
            "[valid] mean Loss = 0.028292 | mean accurracy = 0.991229\n",
            "\n",
            "END OF EPOCH 7\n",
            "[train] mean Loss = 0.036277 | mean accurracy = 0.988584\n",
            "[valid] mean Loss = 0.026901 | mean accurracy = 0.991784\n",
            "\n",
            "END OF EPOCH 8\n",
            "[train] mean Loss = 0.033480 | mean accurracy = 0.989824\n",
            "[valid] mean Loss = 0.025798 | mean accurracy = 0.992261\n",
            "\n",
            "END OF EPOCH 9\n",
            "[train] mean Loss = 0.031248 | mean accurracy = 0.990626\n",
            "[valid] mean Loss = 0.024912 | mean accurracy = 0.992459\n",
            "\n",
            "END OF EPOCH 10\n",
            "[train] mean Loss = 0.029310 | mean accurracy = 0.990959\n",
            "[valid] mean Loss = 0.024145 | mean accurracy = 0.992808\n",
            "\n",
            "END OF EPOCH 11\n",
            "[train] mean Loss = 0.027425 | mean accurracy = 0.991621\n",
            "[valid] mean Loss = 0.023525 | mean accurracy = 0.992801\n",
            "\n",
            "END OF EPOCH 12\n",
            "[train] mean Loss = 0.025703 | mean accurracy = 0.992111\n",
            "[valid] mean Loss = 0.022969 | mean accurracy = 0.992870\n",
            "\n",
            "END OF EPOCH 13\n",
            "[train] mean Loss = 0.024023 | mean accurracy = 0.992596\n",
            "[valid] mean Loss = 0.022460 | mean accurracy = 0.993072\n",
            "\n",
            "END OF EPOCH 14\n",
            "[train] mean Loss = 0.022482 | mean accurracy = 0.993123\n",
            "[valid] mean Loss = 0.021988 | mean accurracy = 0.993142\n",
            "\n",
            "END OF EPOCH 15\n",
            "[train] mean Loss = 0.020934 | mean accurracy = 0.993664\n",
            "[valid] mean Loss = 0.021559 | mean accurracy = 0.993285\n",
            "\n",
            "END OF EPOCH 16\n",
            "[train] mean Loss = 0.019436 | mean accurracy = 0.994171\n",
            "[valid] mean Loss = 0.021219 | mean accurracy = 0.993285\n",
            "\n",
            "END OF EPOCH 17\n",
            "[train] mean Loss = 0.018017 | mean accurracy = 0.994954\n",
            "[valid] mean Loss = 0.020938 | mean accurracy = 0.993491\n",
            "\n",
            "END OF EPOCH 18\n",
            "[train] mean Loss = 0.016588 | mean accurracy = 0.995488\n",
            "[valid] mean Loss = 0.020790 | mean accurracy = 0.993564\n",
            "\n",
            "END OF EPOCH 19\n",
            "[train] mean Loss = 0.015259 | mean accurracy = 0.996113\n",
            "[valid] mean Loss = 0.020725 | mean accurracy = 0.993428\n",
            "\n",
            "END OF EPOCH 20\n",
            "[train] mean Loss = 0.013947 | mean accurracy = 0.996564\n",
            "[valid] mean Loss = 0.020749 | mean accurracy = 0.993428\n",
            "\n",
            "END OF EPOCH 21\n",
            "[train] mean Loss = 0.012738 | mean accurracy = 0.997033\n",
            "[valid] mean Loss = 0.020898 | mean accurracy = 0.993296\n",
            "\n",
            "END OF EPOCH 22\n",
            "[train] mean Loss = 0.011625 | mean accurracy = 0.997409\n",
            "[valid] mean Loss = 0.021212 | mean accurracy = 0.993160\n",
            "\n",
            "END OF EPOCH 23\n",
            "[train] mean Loss = 0.010659 | mean accurracy = 0.997666\n",
            "[valid] mean Loss = 0.021717 | mean accurracy = 0.993024\n",
            "\n",
            "END OF EPOCH 24\n",
            "[train] mean Loss = 0.009854 | mean accurracy = 0.997778\n",
            "[valid] mean Loss = 0.021927 | mean accurracy = 0.993028\n",
            "\n",
            "EARLY STOP\n",
            "\n",
            "[valid] mean Loss = 0.035166 | mean accurracy = 0.989966\n",
            "precision: 0.9875971674919128, recall: 0.9859545230865479, f1: 0.9867751598358154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics on the data"
      ],
      "metadata": {
        "id": "c1-Y5zmVCFm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent class baseline (accuracy)\n",
        "test_speaker['tags'].apply(lambda x: x.count('O')/len(x)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-bqndcpn2P5",
        "outputId": "14bd9251-e252-4793-9aa4-76ecf9e74244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9879597287772806"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision baseline\n",
        "test_speaker['tags'].apply(lambda x: (x.count('I') + x.count('B'))/len(x)).mean()"
      ],
      "metadata": {
        "id": "O4QoxbwXpDLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e249c2-01e6-4b68-e538-0af712b74cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.012040271222719277"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('total number of examples: ', df_speaker.shape[0])\n",
        "\n",
        "print('number of examples where speaker is identified: ', df_speaker[df_speaker.speaker != \"None\"].shape[0])\n",
        "\n",
        "print('number of examples where speaker is identified in text: ', df_speaker['tags'].apply(lambda x: x.count('I') != 0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WukeM3KpxSYT",
        "outputId": "0f46215c-9285-4c5c-a834-160d326ba4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of examples:  688\n",
            "number of examples where speaker is identified:  279\n",
            "number of examples where speaker is identified in text:  240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example of sentence when the speaker is identified but nor present \n",
        "#our system is not able to predict speaker for these\n",
        "\n",
        "df_speaker['not_none'] = df_speaker['speaker'].apply(lambda x: x != \"None\")\n",
        "\n",
        "df_speaker['only_O'] = df_speaker['tags'].apply(lambda x: x.count('I') + x.count('B') == 0)\n",
        "\n",
        "for ind in df_speaker[df_speaker.not_none][df_speaker.only_O].index:\n",
        "  print('text: ', df_speaker['text'][ind])\n",
        "  print('\\nspeaker:\\n', df_speaker['speaker'][ind])\n",
        "  print('---------------------------------------------------------')\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad7eC61PzjoY",
        "outputId": "a9eacd39-4e42-4288-a1e4-d0f2fc626462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  Jeudi, sur France 2, la candidate RN déclarait que \" la peine de mort pourrait passer par un référendum \" puisque \" tout pourrait passer par un référendum \". Ce vendredi, sur BFM, elle est revenue sur ses propos : \" C'est anticonstitutionnel \".\n",
            "\n",
            "speaker:\n",
            " Marine Le Pen\n",
            "---------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-e9df4b320948>:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for ind in df_speaker[df_speaker.not_none][df_speaker.only_O].index:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_speaker['tokenized_text'].apply(lambda x: len(x)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE8fP8Z_RYBR",
        "outputId": "2d4c067c-91cb-4b21-a1d5-718888e6ea39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.29796511627907"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYYrp8nMDeUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
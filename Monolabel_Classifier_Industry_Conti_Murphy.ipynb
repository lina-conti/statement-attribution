{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ],
      "metadata": {
        "id": "XEbZciTigoUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor"
      ],
      "metadata": {
        "id": "Q1wVlfDFwfgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f8HbyRtmlWq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from polyglot.text import Text\n",
        "from polyglot.detect.base import logger as polyglot_logger\n",
        "polyglot_logger.setLevel(\"ERROR\")\n",
        "\n",
        "from copy import copy\n",
        "\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the data \n",
        "\n"
      ],
      "metadata": {
        "id": "MKN6krDPmyhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://drive.google.com/file/d/1-6E4h5lH2AHRUBVJUtchXSggMRYr_-8F/view?usp=share_link'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
        "\n",
        "df = pd.read_csv(path).dropna()\n",
        "df = df.drop_duplicates('text')\n",
        "df"
      ],
      "metadata": {
        "id": "M9LL1mr7mwgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b133aae9-83ef-43dc-d717-5adad57339a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                       speaker  \\\n",
              "0             0             Roselyne Bachelot   \n",
              "1             1                          None   \n",
              "2             2             Roselyne Bachelot   \n",
              "3             3                          None   \n",
              "4             4             Roselyne Bachelot   \n",
              "..          ...                           ...   \n",
              "785         126  Marjolaine Meynier-Millefert   \n",
              "786         127                          None   \n",
              "787         128                          None   \n",
              "788         129                          None   \n",
              "789         130                          None   \n",
              "\n",
              "                                                  text  \n",
              "0    Roselyne Bachelot en campagne à Angoulême : \" ...  \n",
              "1    C'est un métier et à ce jeu, elle a quelques k...  \n",
              "2    * Roselyne Bachelot en campagne à Angoulême : ...  \n",
              "3    \\n\\nC 'est un métier et à ce jeu, elle a quelq...  \n",
              "4    \\n\\n* La graine de l'expérience *\\n\\nUn style ...  \n",
              "..                                                 ...  \n",
              "785  \\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...  \n",
              "786  \\n\\nHabituellement, le samedi matin est un mom...  \n",
              "787  Présidentielle : à Beauvais, le ministre Franc...  \n",
              "788  Le ministre du Commerce extérieur et de l'Attr...  \n",
              "789  Par Patrick Caffin\\n\\nPour les soutiens d'Emma...  \n",
              "\n",
              "[790 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2b36ddd-6785-49c8-a393-5005471430b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>Roselyne Bachelot en campagne à Angoulême : \" ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>C'est un métier et à ce jeu, elle a quelques k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>* Roselyne Bachelot en campagne à Angoulême : ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nC 'est un métier et à ce jeu, elle a quelq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Roselyne Bachelot</td>\n",
              "      <td>\\n\\n* La graine de l'expérience *\\n\\nUn style ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785</th>\n",
              "      <td>126</td>\n",
              "      <td>Marjolaine Meynier-Millefert</td>\n",
              "      <td>\\n\\nPar Pauline SEIGNEUR - Aujourd'hui à 17:23...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>127</td>\n",
              "      <td>None</td>\n",
              "      <td>\\n\\nHabituellement, le samedi matin est un mom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>128</td>\n",
              "      <td>None</td>\n",
              "      <td>Présidentielle : à Beauvais, le ministre Franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>129</td>\n",
              "      <td>None</td>\n",
              "      <td>Le ministre du Commerce extérieur et de l'Attr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>130</td>\n",
              "      <td>None</td>\n",
              "      <td>Par Patrick Caffin\\n\\nPour les soutiens d'Emma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>790 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2b36ddd-6785-49c8-a393-5005471430b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2b36ddd-6785-49c8-a393-5005471430b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2b36ddd-6785-49c8-a393-5005471430b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train test split \n",
        "\n"
      ],
      "metadata": {
        "id": "-EKzlK_Fm8F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "test_length  = int(df.shape[0] * 0.15)\n",
        "\n",
        "test         = df[:test_length]\n",
        "dev          = df[test_length:2*test_length]\n",
        "train        = df[2*test_length:]\n",
        "\n",
        "print(test.shape)\n",
        "print(dev.shape)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "id": "aWKC7uJPnVTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaf4a92-3894-4a5c-cfa3-4fea2cefad25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118, 3)\n",
            "(118, 3)\n",
            "(554, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization and computation of input and output vocabulary"
      ],
      "metadata": {
        "id": "YNSb2R_Eqi3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vocabulary(df, input_vocab, padding='<pad>', unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token \n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "\n",
        "    if input_vocab:\n",
        "      sequences_list = df['text'].apply(lambda x: Text(x).words).to_list()\n",
        "    else:\n",
        "      sequences_list = df['speaker'].str.split(',').to_list()\n",
        "\n",
        "    # Creates the mapping from ids to symbols (a list)\n",
        "    idx2sym = list({element.strip() for sequence in sequences_list for element in sequence})\n",
        "\n",
        "    # Decides whether to include the unknown token\n",
        "    if unknown:\n",
        "      idx2sym.append(unknown)\n",
        "\n",
        "    # Decides whether to include the padding token\n",
        "    if padding:\n",
        "      idx2sym.append(padding)\n",
        "\n",
        "    # Creates the mapping from symbols to ids (a dictionary)\n",
        "    sym2idx = {idx2sym[j]: j for j in range(len(idx2sym))}\n",
        "\n",
        "    # Return the two vocabulary maps idx2sym and sym2idx as a couple\n",
        "    return idx2sym, sym2idx   "
      ],
      "metadata": {
        "id": "YS335uhLsqaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding and decoding sequences "
      ],
      "metadata": {
        "id": "EeEQSmEq3Vs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens to match pad_size if needed\n",
        "    return [sequence[i] if i<len(sequence) else pad_token for i in range(pad_size)]\n",
        "   \n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    return [coding_map[symbol] if symbol in coding_map else coding_map[unk_token] for symbol in sequence]\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings \n",
        "    return [decoding_map[id] for id in sequence]"
      ],
      "metadata": {
        "id": "Tyz_WtyS3VJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloader (batch generator)"
      ],
      "metadata": {
        "id": "c0yxrmY5nWE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_examples(df):\n",
        "    \"\"\"\n",
        "    Returns a list of sentences and a list of tags.\n",
        "    A sentence is a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    paragraphs = df['text'].apply(lambda x: Text(x).words).to_list()\n",
        "    paragraphs = [[word.strip() for word in paragraph] for paragraph in paragraphs]\n",
        "\n",
        "    tags = df['speaker'].str.split(',').to_list()\n",
        "    tags = [[tag.strip() for tag in paragraph_tags] for paragraph_tags in tags]\n",
        "\n",
        "    assert len(paragraphs) == len(tags)\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(len(paragraphs)):\n",
        "        while(tags[i]):\n",
        "            X.append(paragraphs[i])\n",
        "            Y.append([tags[i].pop()])\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "PXc09u1acNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator:\n",
        "\n",
        "        def __init__(self, df, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx \n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym \n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx \n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym  \n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  # Creates 4 encoding maps from datafile \n",
        "                  self.input_idx2sym, self.input_sym2idx  = vocabulary(df, \n",
        "                                                                       input_vocab=True)\n",
        "                  self.output_idx2sym,self.output_sym2idx = vocabulary(df, \n",
        "                                                                       input_vocab=False,\n",
        "                                                                       padding=None)\n",
        "\n",
        "              # Stores the dataset with sentence structure (a list of lists of strings) in the following fields \n",
        "              self.Xtokens, self.Ytokens = df_to_examples(df)\n",
        "      \n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #Batches are lists of lists\n",
        "              \n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "              \n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #If we don't shuffle the train set after each epoch, the model may not converge\n",
        "              shuffle(idxes)\n",
        "              #For efficiency reasons, it is nice to have batches with a similar nb of elements,\n",
        "              #so we don't do useless computations over the padding token\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend] \n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)              \n",
        "              \n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ self.Ytokens[idx] for idx in batch_idxes]\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx,unk_token=self.unk_token)[0] for seq in seqY]\n",
        "                 \n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ],
      "metadata": {
        "id": "HZXHCrZM2xYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model \n",
        "- LSTM encoding of paragraphs \n",
        "- Speaker prediction with a linear layer and softmax"
      ],
      "metadata": {
        "id": "vFVUtZQiniWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    \n",
        "    def __init__(self, patience=7, verbose=True):\n",
        "        \"\"\"\n",
        "        patience (int): How long to wait after last time validation loss improved.\n",
        "                        Default: 7    \n",
        "        verbose (bool): Whether to print a message when early stop is activated.\n",
        "                        Default: True       \n",
        "        \"\"\"\n",
        "        self.patience       = patience\n",
        "        self.counter        = 0         # number of epochs since last improvement\n",
        "        self.best_loss      = None\n",
        "        self.best_accuracy  = None\n",
        "        self.verbose        = verbose\n",
        "\n",
        "    def __call__(self, val_loss, val_accuracy):\n",
        "        \"\"\"\n",
        "        val_loss (float): Validation loss obtained in the current epoch\n",
        "        val_accuracy (float): Validation accuracy obtained in the current epoch (used only for information, early stopping is based on loss)\n",
        "        \"\"\"\n",
        "        if self.best_loss is None:  # if first iteration\n",
        "            self.best_loss      = val_loss\n",
        "            self.best_accuracy  = val_accuracy\n",
        "\n",
        "        if val_loss < self.best_loss: # if improvement\n",
        "            self.best_loss      = val_loss\n",
        "            self.counter        = 0\n",
        "\n",
        "        if val_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy  = val_accuracy  # just for information\n",
        "\n",
        "        if val_loss > self.best_loss: # if no improvement\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "              if self.verbose:\n",
        "                print(\"\\nEARLY STOP\\n\")\n",
        "              return True\n",
        "\n",
        "        return False"
      ],
      "metadata": {
        "id": "nUyOCNf1ne_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core part\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator,embedding_size,hidden_size,device='cpu',\n",
        "                   patience=7,bidirectional=True,verbose=True):\n",
        "        super(NERtagger, self).__init__()        \n",
        "        self.embedding_size    = embedding_size\n",
        "        self.hidden_size       = hidden_size\n",
        "        self.bidirectional     = bidirectional  # whether the lstm is bidirectional or not\n",
        "        self.verbose           = verbose\n",
        "        self.allocate_params(traingenerator,device) \n",
        "        self.early_stopping    = EarlyStopping(verbose=verbose,patience=patience)\n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device):\n",
        "        # Creates fields for nn Layers\n",
        "\n",
        "        invocab_size   = len(datagenerator.input_idx2sym)\n",
        "        pad_idx        = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "        outvocab_size  = len(datagenerator.output_idx2sym)\n",
        "        \n",
        "        self.embeddings = nn.Embedding(invocab_size,\n",
        "                                      self.embedding_size,\n",
        "                                      padding_idx=pad_idx).to(device)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
        "                            hidden_size=self.hidden_size,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=self.bidirectional).to(device) \n",
        "                            # batch_first so it takes input of shape (batch, seq, feature)\n",
        "        \n",
        "        size_X         = self.hidden_size*2 if self.bidirectional else self.hidden_size # this line is necessary so the bidirectional switch works\n",
        "        self.output    = nn.Linear(size_X,outvocab_size).to(device)\n",
        " \n",
        "\n",
        "      def forward(self,X):\n",
        "        # X is of shape batch_size x sequence_length\n",
        "\n",
        "        # Prediction steps:\n",
        "        # embedded_X of shape batch_size x sequence_length x embedding_size\n",
        "        embedded_X  = self.embeddings(X)\n",
        "\n",
        "        # h_n of shape 1 (2 if bidirectional) x batch_size x hidden_size\n",
        "        _, (h_n, _) = self.lstm(embedded_X) \n",
        "        # h_n of shape batch_size x hidden_size (* 2 if bidirectional)\n",
        "        if self.bidirectional:\n",
        "          h_n = torch.cat((h_n[0], h_n[1]), dim=1)\n",
        "        else:\n",
        "          h_n.squeeze(0)\n",
        "\n",
        "        # output of shape batch_size x outvocab_size\n",
        "        return self.output(h_n) \n",
        "\n",
        "\n",
        "      def evaluate(self, datagenerator, batch_size = 64, device = 'cpu'): \n",
        "        '''evaluates the performance of the model on a test set. \n",
        "        calculates recall and precision, considering 'O' tags to be the negative case \n",
        "        and all i tags to be positice cases '''\n",
        "        self.to(device)\n",
        "        #self.eval()\n",
        "        true_neg = 0 \n",
        "        true_pos = 0 \n",
        "        false_neg = 0 \n",
        "        false_pos = 0 \n",
        "        pad_idx   = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "\n",
        "        for batch_x, batch_y in datagenerator.generate_batches(batch_size): \n",
        "          with torch.no_grad():\n",
        "            X_in    = torch.tensor(batch_x).to(device) #batch_size x seq_length\n",
        "            y_gold  = torch.tensor(batch_y).to(device) #batch_size\n",
        "            print('y gold: ', y_gold.shape) \n",
        "            Yhat    = self.forward(X_in) #batch_size x outvocab size \n",
        "            y_pred = torch.argmax(Yhat, dim = 1) #batch_size x 1\n",
        "            print('y pred ', y_pred.shape)\n",
        "\n",
        "            pad_mask   = (y_gold != pad_idx)\n",
        "            pos_mask   = (y_pred != datagenerator.output_sym2idx['None'])\n",
        "            neg_mask   = (y_pred == datagenerator.output_sym2idx['None'])\n",
        "\n",
        "\n",
        "            true_pos  += torch.sum((y_pred==y_gold)*pos_mask*pad_mask)\n",
        "            print('true_pos: ', true_pos)\n",
        "            true_neg  += torch.sum((y_pred == y_gold)*neg_mask*pad_mask)\n",
        "            print('true negL ', true_neg)\n",
        "            false_pos += torch.sum((y_pred != y_gold)*pos_mask*pad_mask)\n",
        "            print('false pos: ', false_pos)\n",
        "            false_neg += torch.sum((y_pred != y_gold)*neg_mask*pad_mask)\n",
        "            print('false neg: ', false_neg)\n",
        "\n",
        "        precision = true_pos/(true_pos+false_pos)\n",
        "        recall    = true_pos/(true_pos+false_neg)\n",
        "        f_score   = 2*((precision*recall)/(precision+recall))\n",
        "        return precision, recall, f_score \n",
        "\n",
        "        \n",
        "      def train(self,traingenerator,validgenerator,epochs,batch_size,device='cpu'): \n",
        "\n",
        "        self.minloss = 10000000 # the min loss found so far on validation data\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        \n",
        "        device    = torch.device(device)\n",
        "        pad_index = traingenerator.input_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "          self.training = True  # Tells PyTorch we are in training mode (so dropout is activated).\n",
        "\n",
        "          epoch_loss = []\n",
        "          batch_accuracies = []\n",
        "          for seqX,seqY in traingenerator.generate_batches(batch_size):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            X = torch.LongTensor(seqX).to(device)\n",
        "            # Y is of shape batch_size\n",
        "            Y = torch.LongTensor(seqY).to(device)\n",
        "\n",
        "            # Yhat is of shape batch_size x nb_classes\n",
        "            Yhat = self.forward(X)\n",
        "\n",
        "            loss = loss_fnc(Yhat, Y)\n",
        "            loss.backward()\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "            optimizer.step() # Updates the parameters\n",
        "\n",
        "            #Accuracy computation\n",
        "            mask    = (Y != pad_index)\n",
        "            Yargmax = torch.argmax(Yhat,dim=1)\n",
        "            correct = torch.sum((Yargmax == Y) * mask)\n",
        "            total   = torch.sum(mask)\n",
        "            batch_accuracies.append(float(correct)/float(total))\n",
        "\n",
        "          if self.verbose:\n",
        "            print(f\"\\nEND OF EPOCH {epoch}\")\n",
        "            print(f\"[train] mean Loss = {sum(epoch_loss) / len(epoch_loss):.6f} | mean accurracy = {sum(batch_accuracies) / len(batch_accuracies):.6f}\")\n",
        "\n",
        "          # Evaluation\n",
        "          # This will automatically save the model with minimum loss\n",
        "          valid_loss, valid_accuracy = self.validate(validgenerator,\n",
        "                                                     batch_size, \n",
        "                                                     device=device,\n",
        "                                                     save_min_model=True)\n",
        "          \n",
        "          # Early stopping\n",
        "          if self.early_stopping(valid_loss, valid_accuracy):\n",
        "            return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "        # The train function returns the best dev accuracy \n",
        "        # and the number of epochs it trained for.\n",
        "        return self.early_stopping.best_accuracy, epoch\n",
        "\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cpu',save_min_model=False):\n",
        "\n",
        "          self.training = False # Tells PyTorch we are in evaluation/inference mode (so dropout is deactivated).\n",
        "          \n",
        "          batch_accurracies = []\n",
        "          batch_losses      = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY) in datagenerator.generate_batches(batch_size):\n",
        "                with torch.no_grad():   \n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device)\n",
        "                \n",
        "                  Yhat = self.forward(X)\n",
        "\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask    = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  total   = torch.sum(mask)\n",
        "                  batch_accurracies.append(float(correct)/float(total))\n",
        "\n",
        "          L = len(batch_losses)                  \n",
        "          valid_loss = sum(batch_losses)/L\n",
        "          valid_accuracy = sum(batch_accurracies)/L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "          if self.verbose:\n",
        "            print('[valid] mean Loss = %f | mean accurracy = %f'%(valid_loss,valid_accuracy))\n",
        "\n",
        "          return valid_loss, valid_accuracy # used for early stopping in train"
      ],
      "metadata": {
        "id": "MRDC2F7qCHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Q0mUSIOKhyBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 64\n",
        "hidden_size = 128\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "trainset = DataGenerator(train)\n",
        "validset = DataGenerator(dev,parentgenerator=trainset)\n",
        "testset  = DataGenerator(test,parentgenerator=trainset)\n",
        "tagger   = NERtagger(trainset,embed_size,hidden_size,bidirectional=True,device='cuda',patience=10)\n",
        "tagger.train(trainset,validset,epochs,batch_size,device='cuda')\n",
        "tagger.validate(testset,batch_size,device='cuda')\n",
        "\n",
        "p, r, f = tagger.evaluate(testset)\n",
        "print(f'precision: {p}, recall: {r}, f1: {f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNjN1-mpSUe6",
        "outputId": "4aef5c33-cbfa-4f00-83a2-fdfe0ecaba47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "END OF EPOCH 0\n",
            "[train] mean Loss = 4.819181 | mean accurracy = 0.240625\n",
            "[valid] mean Loss = 4.544145 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 1\n",
            "[train] mean Loss = 4.208470 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.717690 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 2\n",
            "[train] mean Loss = 3.087030 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.729966 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 3\n",
            "[train] mean Loss = 2.870576 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.786962 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 4\n",
            "[train] mean Loss = 2.883230 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.737986 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 5\n",
            "[train] mean Loss = 2.810983 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.743418 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 6\n",
            "[train] mean Loss = 2.736101 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.753461 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 7\n",
            "[train] mean Loss = 2.680506 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.746584 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 8\n",
            "[train] mean Loss = 2.599585 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.735249 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 9\n",
            "[train] mean Loss = 2.491412 | mean accurracy = 0.468750\n",
            "[valid] mean Loss = 2.724789 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 10\n",
            "[train] mean Loss = 2.364551 | mean accurracy = 0.475000\n",
            "[valid] mean Loss = 2.705773 | mean accurracy = 0.549603\n",
            "\n",
            "END OF EPOCH 11\n",
            "[train] mean Loss = 2.212331 | mean accurracy = 0.501563\n",
            "[valid] mean Loss = 2.672070 | mean accurracy = 0.541791\n",
            "\n",
            "END OF EPOCH 12\n",
            "[train] mean Loss = 2.101516 | mean accurracy = 0.523438\n",
            "[valid] mean Loss = 2.669829 | mean accurracy = 0.526166\n",
            "\n",
            "END OF EPOCH 13\n",
            "[train] mean Loss = 1.911269 | mean accurracy = 0.545312\n",
            "[valid] mean Loss = 2.660815 | mean accurracy = 0.533978\n",
            "\n",
            "END OF EPOCH 14\n",
            "[train] mean Loss = 1.780723 | mean accurracy = 0.554688\n",
            "[valid] mean Loss = 2.673777 | mean accurracy = 0.541915\n",
            "\n",
            "END OF EPOCH 15\n",
            "[train] mean Loss = 1.723688 | mean accurracy = 0.570312\n",
            "[valid] mean Loss = 2.788908 | mean accurracy = 0.486979\n",
            "\n",
            "END OF EPOCH 16\n",
            "[train] mean Loss = 1.696860 | mean accurracy = 0.553125\n",
            "[valid] mean Loss = 2.748213 | mean accurracy = 0.471230\n",
            "\n",
            "END OF EPOCH 17\n",
            "[train] mean Loss = 1.621642 | mean accurracy = 0.593750\n",
            "[valid] mean Loss = 2.733155 | mean accurracy = 0.549727\n",
            "\n",
            "END OF EPOCH 18\n",
            "[train] mean Loss = 1.355630 | mean accurracy = 0.621875\n",
            "[valid] mean Loss = 2.660876 | mean accurracy = 0.518353\n",
            "\n",
            "END OF EPOCH 19\n",
            "[train] mean Loss = 1.194562 | mean accurracy = 0.664062\n",
            "[valid] mean Loss = 2.703909 | mean accurracy = 0.510665\n",
            "\n",
            "END OF EPOCH 20\n",
            "[train] mean Loss = 1.089645 | mean accurracy = 0.695312\n",
            "[valid] mean Loss = 2.772861 | mean accurracy = 0.503100\n",
            "\n",
            "END OF EPOCH 21\n",
            "[train] mean Loss = 0.954702 | mean accurracy = 0.745313\n",
            "[valid] mean Loss = 2.712975 | mean accurracy = 0.558036\n",
            "\n",
            "END OF EPOCH 22\n",
            "[train] mean Loss = 0.854832 | mean accurracy = 0.759375\n",
            "[valid] mean Loss = 2.739886 | mean accurracy = 0.558036\n",
            "\n",
            "END OF EPOCH 23\n",
            "[train] mean Loss = 0.770360 | mean accurracy = 0.790625\n",
            "[valid] mean Loss = 2.695558 | mean accurracy = 0.565848\n",
            "\n",
            "EARLY STOP\n",
            "\n",
            "[valid] mean Loss = 3.228799 | mean accurracy = 0.447917\n",
            "y gold:  torch.Size([64])\n",
            "y pred  torch.Size([64])\n",
            "true_pos:  tensor(3)\n",
            "true negL  tensor(42)\n",
            "false pos:  tensor(5)\n",
            "false neg:  tensor(14)\n",
            "y gold:  torch.Size([64])\n",
            "y pred  torch.Size([64])\n",
            "true_pos:  tensor(5)\n",
            "true negL  tensor(65)\n",
            "false pos:  tensor(15)\n",
            "false neg:  tensor(43)\n",
            "y gold:  torch.Size([4])\n",
            "y pred  torch.Size([4])\n",
            "true_pos:  tensor(6)\n",
            "true negL  tensor(65)\n",
            "false pos:  tensor(18)\n",
            "false neg:  tensor(43)\n",
            "precision: 0.25, recall: 0.12244898080825806, f1: 0.16438356041908264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics on the data"
      ],
      "metadata": {
        "id": "aRxMpNsPu5X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests\n",
        "\n",
        "#only 75% of gold labels in test set have been seen by train \n",
        "#considereing the fact that 50% of these are 'None', it may be a problem\n",
        "shared_labels = test['speaker'].isin(train['speaker'].tolist())\n",
        "sum(shared_labels)/len(shared_labels)"
      ],
      "metadata": {
        "id": "q58i3Oyeq0fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "speakers_list = df['speaker'].tolist()\n",
        "speakers_list = [speaker.split(',') for speaker in speakers_list]\n",
        "speakers_list = list(itertools.chain(*speakers_list))\n",
        "speakers_list = [speaker.strip() for speaker in speakers_list]\n",
        "\n",
        "speakers_df = pd.DataFrame(speakers_list)\n",
        "speakers_df.value_counts().shape[0]"
      ],
      "metadata": {
        "id": "JEOCaoBKh9pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_speakers_list = train['speaker'].tolist()\n",
        "train_speakers_list = [speaker.split(',') for speaker in train_speakers_list]\n",
        "train_speakers_list = list(itertools.chain(*train_speakers_list))\n",
        "train_speakers_list = [speaker.strip() for speaker in train_speakers_list]\n",
        "\n",
        "train_speakers_df = pd.DataFrame(train_speakers_list)\n",
        "train_speakers_df.value_counts().shape[0]"
      ],
      "metadata": {
        "id": "RHDmFNoxqme1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_speakers_list = test['speaker'].tolist()\n",
        "test_speakers_list = [speaker.split(',') for speaker in test_speakers_list]\n",
        "test_speakers_list = list(itertools.chain(*test_speakers_list))\n",
        "test_speakers_list = [speaker.strip() for speaker in test_speakers_list]\n",
        "\n",
        "test_speakers_df = pd.DataFrame(test_speakers_list)\n",
        "test_speakers_df.value_counts().shape[0]"
      ],
      "metadata": {
        "id": "Z2yg2xFqq--F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shared_labels = test_speakers_df.isin(train_speakers_list)\n",
        "shared_labels.sum()/shared_labels.shape[0]"
      ],
      "metadata": {
        "id": "AUqojM0urdKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_speakers_list)"
      ],
      "metadata": {
        "id": "rTwbjpG8xJTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_speakers_list) - shared_labels.sum()"
      ],
      "metadata": {
        "id": "3ttS5XOLxL4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Accuracy\n",
        "\n",
        "majority_class_test = test_speakers_df.apply(lambda x: x == 'None')\n",
        "majority_class_test.sum() / majority_class_test.shape[0]"
      ],
      "metadata": {
        "id": "iMar7z5wxdmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline precision\n",
        "\n",
        "majority_class_test = test_speakers_df.apply(lambda x: x == 'None')\n",
        "1-(majority_class_test.sum() / majority_class_test.shape[0])"
      ],
      "metadata": {
        "id": "jQKuD3H4O04i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}